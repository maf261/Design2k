---
title: "Design 2k"
author: "Fernando Bastos"
date: "7 de fevereiro de 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Rendimento de Liquefação e Número de Hidroxilas

Fatores sob análise:

\begin{array}{cccc}
\hline
&&Níveis&&\\
\hline
Fatores                      &    -1&  0 	&  1 \\
 	  \hline
\textrm{X1: catalyst amount (C)}      &   2\%	& 5\% & 7\% \\
\textrm{X2: time of reaction (t)}     &   0.5h	& 1h 	    & 1.5h \\
\textrm{X3: ratio biomass/solvent (R)}&   2:1	& 3.5:1 	& 5:1 \\
 	  \hline
\end{array}

```{r}
url <- "https://rawcdn.githack.com/maf261/Design2k/3ba1c025ab8fca9857cebc7112ec14b61c641f03/Tab1.txt"
dados <- read.csv(url, sep = "")
names(dados) <- c("X1","X2","X3","Y")
str(dados)
```

```{r}
## Definições básicas do experimento
## Número de fatores
k <- 3
## Número de níveis
x1 <- x2 <- x3 <- 2
## Número de repetições
r <- 1
n <- r*2^k
Y <- dados$Y
##----------------------------------------------------------------------
## Montando a tabela de sinais
tab <- model.matrix(~ X1 * X2 * X3, data = dados)
tab
```

Uma forma de verificar quais efeitos são importantes é através de um gráfico de probabilidade normal para a estimativa dos efeitos. Lembre-se que, sob a hipótses nula, todos os parâmetros do modelo são iguais a zero, e pela definição do termo de erro do modelo, se os parâmetros são iguais a zero, então sobra apenas o erro que possui média 0 e variância constante $\sigma^2$. Dessa forma, se a hipótese nula for verdadeira, esperamos que os efeitos tenham também média 0, e fiquem em cima da linha em um gráfico de probabilidade normal. Os efeitos que se afastarem muito da linha são aqueles que possuem média diferente de zero, e portanto, são aqueles que temos interesse.

```{r}
##----------------------------------------------------------------------
## a) Gráfico q-q dos efeitos
tab <- model.matrix(~ X1*X2*X3, data = dados)
contr <- t(tab[, -1]) %*% dados$Y
(ef <- contr/(r*2^(k-1)))
aux <- qqnorm(ef, col = 2, pch = 19); qqline(ef)
text(aux$x, aux$y, rownames(aux$y), cex = 0.8, pos = 1)
```

Através do gráfico acima, vemos que o efeito mais discrepante é o X1. De maneira geral, as interações ficaram no centro, o que mostra que interações podem ser consideradas como nulas. Portanto, para sermos conservadores, podemos ajustar agora um modelo considerando apenas o fator X1.

Antes, vejamos o gráfico de Pareto.

```{r}
library("qualityTools")
fdo=facDesign(k=3,centerCube=3)
(fdo=randomize(fdo, so=TRUE))
response(fdo) <- dados$Y
names(fdo) = c( "Catalyst" , "Time" ,"Ratio" , "Y") #optional
lows(fdo) = c(2,0.5,2) #optional
highs(fdo)= c(7,1.5,5)#optional
summary(fdo) #information about the factorial design
effectPlot(fdo,classic = TRUE)
interactionPlot(fdo)
par(mfrow = c(1,2))
paretoPlot(fdo)
normalPlot(fdo)

```

```{r}
##----------------------------------------------------------------------
## b) Análise de variância para confirmar impressões de (a)
m0 <- lm(Y ~ (X1*X2*X3), data = dados)
anova(m0)
summary(m0)
```

```{r}
##----------------------------------------------------------------------
## c) Avaliar se existe falta de ajuste
## Separa os pontos fatoriais dos centrais e calcula tamanho das
## amostras
yf <- dados$Y[dados$X1 != 0] # y dos pontos fatoriais
yc <- dados$Y[dados$X1 == 0] # y do ponto central (0,0)
(nf <- length(yf))
(nc <- length(yc))
## Médias
c(mean(yf), mean(yc))
diff(c(mean(yf), mean(yc)))
```

A SQ do erro puro mede a distância das observações do ponto central em relação à sua média
```{r}
## Erro experimental usando pontos centrais
(SQpuro <- sum((yc - mean(yc))^2))
```

Como só existe uma média, então essa SQ está associada à $n_c−1$ graus de liberdade. Dessa forma, podemos obter uma estimativa do “erro puro”, ou seja, independente do modelo adotado

```{r}
(MQpuro <- SQpuro/(nc-1))
```

Agora podemos calcular a SQ devido à curvatura, ou à falta de ajuste, conforme mostrado anteriormente

```{r}
## lof = lack of fit
(SQlof <- (nf * nc * (mean(yc) - mean(yf))^2)/(nf + nc))
```

que possui apenas um grau de liberdade (portanto SQlof = MQlof). Como vimos, o teste F para a falta de ajuste vem da razão entre MQlof e MQpuro

```{r}
(Flof <- SQlof/MQpuro)
## Calculando o p-valor associado, temos
pf(Flof, 1, nc - 1, lower.tail = FALSE)
```

Ou seja, não rejeitamos a hipótese de que o modelo linear é adequado (ou de que não existe falta de ajuste). De outra forma, podemos proceder:

```{r}
## Modelo desconsiderando os pontos centrais
m0 <- lm(Y ~ X1 * X2 * X3, data = dados,
         subset = X1!= 0)
anova(m0)
```

Note que dessa forma não temos uma estimativa do erro.

```{r}
## Modelo considerando os pontos centrais
m1 <- lm(Y ~ X1 * X2 * X3, data = dados)
anova(m1)
```

Mesmo sem repetição dos fatores, obtemos uma estimativa do erro devido às repetições do ponto central. Mas note que essa estimativa pode ser viesada pois não consideramos um termo quadrático no modelo para incorporar a falta de ajuste. Caso não exista falta de ajuste, ou seja o modelo linear é adequado, então esta estimativa está correta (não viesada). Mas se o modelo linear não for adequado a estimativa será viesada. Para incluir um termo que define a falta de ajuste podemos criar uma nova variável indicadora para os pontos fatoriais e os pontos centrais. Obtemos esse termo elevendo qualquer coluna de fator ao quadrado:

```{r}
## Teste para falta de ajuste
dados$lof <- dados$X1^2
dados
```

lof aqui significa “lack of fit”. Note que essa coluna somente indica quais observações são dos eixos fatoriais e quais são do ponto central

Isso irá fazer com que a média do plano fatorial $({y}_f)$ seja contrastada com a média do plano dos pontos centrais $({y}_c).$ Agora podemos ajustar um novo modelo com esse termo

```{r}
m2 <- lm(Y ~ (X1*X2*X3) + lof, data = dados)
anova(m2)
```

Note que o teste F para SQlof está de fato testando se esse termo é importante, ou em outras palavras, se a diferença entre as médias dos eixos dos fatores é significativa. Um TRV entre os modelos com e sem lof mostra o mesmo resultado.

```{r}
#Comparação de modelos
anova(m1, m2)
```

Nesse caso, não rejeitamos a hipótese de que essas médias são iguas e concluimos que não há falta de ajuste, e que o modelo linear é adequado. Assim, podemos redefinir o modelo sem esse termo

```{r}
mf <- update(m1, . ~ . -lof)
anova(mf)
```

Como as interações e os fatores X2 e X3 são não significativos, então também podemos retira-los do modelo. No entanto, o efeito da interação X1:X2 foi inicialmente indicado como forte. Por isso, podemos agora atualizar o modelo e na dúvida, manter a interação X1:X2 para avaliação, e por consequência devemos manter também X2 pelo princípio da marginalidade.

```{r}
mf <- lm(Y ~ X1*X2, data = dados)
anova(mf)
```

Dessa forma temos uma estimativa de erro não viesada e um modelo parcimonioso para descrever o processo. Podemos então avaliar os resíduos e fazer as predições:

```{r}
## d) Avaliação dos pressupostos
## Para o modelo sem lof
res <- residuals(mf)
qqnorm(res); qqline(res)
```

```{r}
## Resíduo vs preditor
par(mfrow = c(1, 3))
with(dados, {
    plot(res ~ X1)
    abline(h = 0, lty = 2, col = 2)
    plot(res ~ X2)
    abline(h = 0, lty = 2, col = 2)
    plot(res ~ X3)
    abline(h = 0, lty = 2, col = 2)
})
```

```{r}
par(mfrow = c(1, 1))

##----------------------------------------------------------------------
## Predições
## Predição para as combinações únicas dos fatores
pred <- data.frame(X1 = dados$X1,
                   X2 = dados$X2,
                   X3 = dados$X3)
pred$y <- predict(mf, newdata = pred)
pred
```

```{r}
## Verifica a projeção
proj(mf)
```

```{r}
cbind(pred, yproj = apply(proj(mf)[,-4], 1, sum))
```

```{r}
## Predição para um intervalo de valores entre os níveis baixo e alto
## dos fatores
pred <- expand.grid(X1 = seq(-1, 1, length.out = 30),
                    X2 = seq(-1, 1 ,length.out = 30),
                    X3 = seq(-1, 1 ,length.out = 30))
pred$y <- predict(mf, newdata = pred)
library("lattice")
## Vários formas de visualizar
wireframe(y ~ X1 + X2, data = pred, drape = TRUE)
wireframe(y ~ X1 + X3, data = pred, drape = TRUE)
wireframe(y ~ X2 + X3, data = pred, drape = TRUE)
```

```{r}
levelplot(y ~ X1+X2, data = pred, cuts = 90,
          col.regions = heat.colors)
levelplot(y ~ X1+X3, data = pred, cuts = 90,
          col.regions = heat.colors)
levelplot(y ~ X2+X3, data = pred, cuts = 90,
          col.regions = heat.colors)
```

